{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6055bf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_key_id='AKIA3FDNNPYVQ5OJWHMJ'\n",
    "aws_secret_key='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "297dc5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos imports\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.linalg import VectorUDT\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql.functions import PandasUDFType\n",
    "from pyspark.sql.types import IntegerType, StringType, ArrayType\n",
    "\n",
    "import boto3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73062f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/23 05:21:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# On crée notre environnement Spark\n",
    "spark = SparkSession.builder.appName('P8_OCR_VLE').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa8027d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3e45e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(img_path):\n",
    "    \"\"\"\n",
    "    Prend le chemin dans un bucket S3 d'un objet (une image), le lit et\n",
    "    le transforme sous la forme d'une liste.\n",
    "\n",
    "            Parameters:\n",
    "                img_path : le chemin de l'image dans notre bucket S3\n",
    "    \"\"\"\n",
    "    \n",
    "    # On récupère nos images en se connectant à notre bucket S3\n",
    "    s3 = boto3.resource('s3', aws_access_key_id=aws_key_id, aws_secret_access_key=aws_secret_key)\n",
    "    bucket = s3.Bucket('ocproj8')\n",
    "    # On récupère les objets dans notre bucket\n",
    "    img = img_path.replace('s3://ocproj8/Data/', '')\n",
    "    bucket_file = bucket.Object(img)\n",
    "    s3_response = bucket_file.get()\n",
    "    file_stream = s3_response['Body']\n",
    "    print(file_stream)\n",
    "    image = Image.open(file_stream)\n",
    "    \n",
    "    # On enlève les images qui ne retournent rien\n",
    "    if image is None:\n",
    "        image = 0\n",
    "        \n",
    "    else:\n",
    "        image = np.asarray(image)\n",
    "        image = np.resize(image, (299, 299, 3))\n",
    "        image = image.flatten().tolist()\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c790dc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pretrained():\n",
    "    \"\"\"\n",
    "    Retourne notre modèle (InceptionV3), sans la couche la plus haute\n",
    "    (couche de classification) et on y ajoute manuellement les poids pré-entraînés.\n",
    "    \"\"\"\n",
    "    \n",
    "    model = InceptionV3(weights=None, include_top=False)\n",
    "    model.set_weights(model_weights.value)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b95f63c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(data):\n",
    "    \"\"\"\n",
    "    Prend une liste représentative de nos images, les transforme\n",
    "    en array et change le format de l'image. Retourne les images\n",
    "    auxquelles on applique le preprocessing propre à notre modèle.\n",
    "    \"\"\"\n",
    "    \n",
    "    image = np.asarray(data)\n",
    "    image = np.resize(image, (299, 299, 3))\n",
    "\n",
    "    return preprocess_input(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77af034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize_series(model, content_series):\n",
    "    \"\"\"\n",
    "    Récupère toutes nos images pour y appliquer notre preprocessing\n",
    "    et on applique notre modèle, avant de faire une classification.\n",
    "    Retourne une série composée de nos features.\n",
    "    \n",
    "            Parameters:\n",
    "                model : notre modèle (InceptionV3 ici)\n",
    "                content_series : nos données images\n",
    "    \"\"\"\n",
    "    \n",
    "    model_input = np.stack(content_series.map(preprocess_img)) \n",
    "    preds = model.predict(model_input)\n",
    "    model_output = [x.flatten() for x in preds]\n",
    "    return pd.Series(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d714f6bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/pyspark/sql/pandas/functions.py:398: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "@pandas_udf('array<float>', \"long\", PandasUDFType.SCALAR_ITER)\n",
    "def udf_featurize_series(content_series_iter):\n",
    "    \"\"\"\n",
    "    UDF (User Defined Function) wrapper pour notre fonction de featurisation.\n",
    "    Retourne une colonne de DataFrame Spark de type ArrayType(FloatType)\n",
    "    \n",
    "            Parameters:\n",
    "            content_series_iter : série de nos données images\n",
    "    \"\"\"\n",
    "    model = model_pretrained()\n",
    "    for content_series in content_series_iter:\n",
    "        yield featurize_series(model, content_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50d14ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3', aws_access_key_id=aws_key_id, aws_secret_access_key=aws_secret_key)\n",
    "\n",
    "bucket = s3.Bucket('ocproj8')\n",
    "\n",
    "paths = []\n",
    "for file in bucket.objects.all():\n",
    "    if file.key.split(\"/\")[0] == \"Data\":\n",
    "        paths.append(file.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be5916b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_paths = sc.parallelize(\n",
    "    paths\n",
    ")  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68b2617f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Partitions: 2\n",
      "----------\n",
      "Action: First element: Data/Apple/0_100.jpg\n",
      "----------\n",
      "['Data/Apple/0_100.jpg', 'Data/Apple/1_100.jpg', 'Data/Apricot/0_100.jpg', 'Data/Apricot/1_100.jpg', 'Data/Avocado/0_100.jpg', 'Data/Avocado/1_100.jpg', 'Data/Banana/0_100.jpg', 'Data/Banana/1_100.jpg', 'Data/Beetroot/0_100.jpg', 'Data/Beetroot/1_100.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lst_path = (\n",
    "    rdd_paths.collect()\n",
    ")  # Return a list that contains all of the elements in the RDD\n",
    "print(\"Number of Partitions: \" + str(rdd_paths.getNumPartitions()))\n",
    "print(\"--\" * 5)\n",
    "print(\"Action: First element: \" + str(rdd_paths.first()))\n",
    "print(\"--\" * 5)\n",
    "print(lst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb88ea2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "afterSSSSSSSSSSS\n"
     ]
    }
   ],
   "source": [
    "# On se connecte à notre bucket S3\n",
    "session = boto3.session.Session( aws_key_id,aws_secret_key)\n",
    "\n",
    "s3_client = session.client(service_name='s3', region_name='eu-west-3', aws_access_key_id=aws_key_id,aws_secret_access_key=aws_secret_key)\n",
    "print(\"afterSSSSSSSSSSS\")\n",
    "# Et on se prépare à lire nos fichiers\n",
    "prefix = 'Data/'\n",
    "sub_folders = s3_client.list_objects_v2(Bucket='ocproj8', Prefix=prefix,  Delimiter = \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ed86ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': 'VMHRF71T6QQ8BS38', 'HostId': 'kCqWMGXuoQ7BvAQl+84igVnoVACElqytpIbvawMu4NNi5qjtohhsKgKumgBc68h1eUmQSl7IVVA=', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amz-id-2': 'kCqWMGXuoQ7BvAQl+84igVnoVACElqytpIbvawMu4NNi5qjtohhsKgKumgBc68h1eUmQSl7IVVA=', 'x-amz-request-id': 'VMHRF71T6QQ8BS38', 'date': 'Sun, 23 Oct 2022 05:21:43 GMT', 'x-amz-bucket-region': 'eu-west-3', 'content-type': 'application/xml', 'transfer-encoding': 'chunked', 'server': 'AmazonS3'}, 'RetryAttempts': 0}, 'IsTruncated': False, 'Name': 'ocproj8', 'Prefix': 'Data/', 'Delimiter': '/', 'MaxKeys': 1000, 'CommonPrefixes': [{'Prefix': 'Data/Apple/'}, {'Prefix': 'Data/Apricot/'}, {'Prefix': 'Data/Avocado/'}, {'Prefix': 'Data/Banana/'}, {'Prefix': 'Data/Beetroot/'}], 'EncodingType': 'url', 'KeyCount': 5}\n"
     ]
    }
   ],
   "source": [
    "print(sub_folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b04655",
   "metadata": {},
   "source": [
    " On lit les fichiers présent dans notre dossiers \"Data\"\n",
    "#On récupère l'emplacement des fichiers\n",
    "lst_path = []\n",
    "if 'Contents' in sub_folders:\n",
    "    for key in sub_folders['Contents']:\n",
    "        file = key['Key']\n",
    "        file = file.replace(prefix + '/', '')\n",
    "        lst_path.append('s3://ocproj8/Data/' + file)\n",
    "else:\n",
    "    print(\"No objects returned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c9bbe78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# On crée notre DataFrame et on y met l'emplacement de fichiers\n",
    "rdd = spark.sparkContext.parallelize(lst_path)\n",
    "row_rdd = rdd.map(lambda x: Row(x))\n",
    "df_pyspark = spark.createDataFrame(row_rdd, ['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d6cfc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|path                  |\n",
      "+----------------------+\n",
      "|Data/Apple/0_100.jpg  |\n",
      "|Data/Apple/1_100.jpg  |\n",
      "|Data/Apricot/0_100.jpg|\n",
      "|Data/Apricot/1_100.jpg|\n",
      "|Data/Avocado/0_100.jpg|\n",
      "|Data/Avocado/1_100.jpg|\n",
      "|Data/Banana/0_100.jpg |\n",
      "+----------------------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# On vérifie\n",
    "df_pyspark.show(7, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa3dfee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère nos labels\n",
    "df_pyspark = df_pyspark.withColumn('label', split(col('path'), '/').getItem(1))\n",
    "# On ajoute une colonne avec nos données images\n",
    "udf_image = udf(load_img, ArrayType(IntegerType()))\n",
    "df_pyspark = df_pyspark.withColumn('data', udf_image('path'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d086c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<botocore.response.StreamingBody object at 0x7fd693861f90>          (0 + 1) / 1]\n",
      "<botocore.response.StreamingBody object at 0x7fd693542450>\n",
      "<botocore.response.StreamingBody object at 0x7fd693326590>\n",
      "<botocore.response.StreamingBody object at 0x7fd6935748d0>\n",
      "<botocore.response.StreamingBody object at 0x7fd6937b5f10>\n",
      "<botocore.response.StreamingBody object at 0x7fd6939e77d0>          (0 + 1) / 1]\n",
      "<botocore.response.StreamingBody object at 0x7fd693302550>\n",
      "<botocore.response.StreamingBody object at 0x7fd6a333c250>\n",
      "<botocore.response.StreamingBody object at 0x7fd693574390>\n",
      "<botocore.response.StreamingBody object at 0x7fd693995110>\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------------------+\n",
      "|                path|  label|                data|\n",
      "+--------------------+-------+--------------------+\n",
      "|Data/Apple/0_100.jpg|  Apple|[254, 255, 255, 2...|\n",
      "|Data/Apple/1_100.jpg|  Apple|[254, 255, 255, 2...|\n",
      "|Data/Apricot/0_10...|Apricot|[255, 251, 248, 2...|\n",
      "|Data/Apricot/1_10...|Apricot|[255, 255, 248, 2...|\n",
      "|Data/Avocado/0_10...|Avocado|[255, 255, 255, 2...|\n",
      "|Data/Avocado/1_10...|Avocado|[255, 255, 255, 2...|\n",
      "|Data/Banana/0_100...| Banana|[255, 255, 255, 2...|\n",
      "+--------------------+-------+--------------------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# On vérifie de nouveau\n",
    "df_pyspark.show(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31be244d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<botocore.response.StreamingBody object at 0x7fd6932f7210>          (0 + 1) / 1]\n",
      "<botocore.response.StreamingBody object at 0x7fd69332b850>\n",
      "<botocore.response.StreamingBody object at 0x7fd693a05610>\n",
      "<botocore.response.StreamingBody object at 0x7fd693b57590>\n",
      "<botocore.response.StreamingBody object at 0x7fd693861910>\n",
      "<botocore.response.StreamingBody object at 0x7fd6939e7750>          (0 + 1) / 1]\n",
      "<botocore.response.StreamingBody object at 0x7fd69332ea90>\n",
      "<botocore.response.StreamingBody object at 0x7fd6937c98d0>\n",
      "<botocore.response.StreamingBody object at 0x7fd6939d8090>\n",
      "<botocore.response.StreamingBody object at 0x7fd6939c4d90>\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+-------------+--------------------+\n",
      "|                path|  label|label_encoded|                data|\n",
      "+--------------------+-------+-------------+--------------------+\n",
      "|Data/Apple/0_100.jpg|  Apple|            0|[254, 255, 255, 2...|\n",
      "|Data/Apple/1_100.jpg|  Apple|            0|[254, 255, 255, 2...|\n",
      "|Data/Apricot/0_10...|Apricot|            1|[255, 251, 248, 2...|\n",
      "|Data/Apricot/1_10...|Apricot|            1|[255, 255, 248, 2...|\n",
      "|Data/Avocado/0_10...|Avocado|            2|[255, 255, 255, 2...|\n",
      "|Data/Avocado/1_10...|Avocado|            2|[255, 255, 255, 2...|\n",
      "|Data/Banana/0_100...| Banana|            3|[255, 255, 255, 2...|\n",
      "+--------------------+-------+-------------+--------------------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# On va utiliser un StringIndexer pour encoder nos labels\n",
    "stringIndexer = StringIndexer(inputCol='label', outputCol='label_encoded')\n",
    "sI = stringIndexer.fit(df_pyspark)\n",
    "\n",
    "# On encode et on convertit nos labels en Integer (lisibilité)\n",
    "image_df = sI.transform(df_pyspark)\n",
    "image_df = image_df.withColumn('label_encoded', col('label_encoded').cast(IntegerType()))\n",
    "\n",
    "# On réorganise nos colonnes (lisibilité)\n",
    "image_df = image_df.select('path', 'label', 'label_encoded', 'data')\n",
    "image_df.show(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a17224af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 05:22:49.822243: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-23 05:22:49.861873: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300035000 Hz\n",
      "2022-10-23 05:22:49.862186: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d9db3c7de0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-10-23 05:22:49.862204: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "# On charge notre model et les poids associés\n",
    "model = InceptionV3(include_top=False)\n",
    "model_weights = spark.sparkContext.broadcast(model.get_weights()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edb6e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On applique notre preprocessing\n",
    "features_df = image_df.select(col('path'), col('label'), col('label_encoded'),\n",
    "                              udf_featurize_series('data').alias('features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cfdf478",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<botocore.response.StreamingBody object at 0x7fd6932f7150>          (0 + 1) / 1]\n",
      "<botocore.response.StreamingBody object at 0x7fd693321d10>\n",
      "<botocore.response.StreamingBody object at 0x7fd693a35bd0>\n",
      "<botocore.response.StreamingBody object at 0x7fd6939e0250>\n",
      "<botocore.response.StreamingBody object at 0x7fd693b7a810>\n",
      "2022-10-23 05:23:07.903560: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-23 05:23:07.908674: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300035000 Hz\n",
      "2022-10-23 05:23:07.908914: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cce5c77de0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-10-23 05:23:07.908943: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "<botocore.response.StreamingBody object at 0x7fd69330ea90>          (0 + 1) / 1]\n",
      "<botocore.response.StreamingBody object at 0x7fd6937c3ed0>\n",
      "<botocore.response.StreamingBody object at 0x7fd6937c9690>\n",
      "<botocore.response.StreamingBody object at 0x7fd693315d50>\n",
      "<botocore.response.StreamingBody object at 0x7fd693b69c50>\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+-------------+--------------------+\n",
      "|                path|  label|label_encoded|            features|\n",
      "+--------------------+-------+-------------+--------------------+\n",
      "|Data/Apple/0_100.jpg|  Apple|            0|[15.928615, 0.0, ...|\n",
      "|Data/Apple/1_100.jpg|  Apple|            0|[12.5887785, 0.70...|\n",
      "|Data/Apricot/0_10...|Apricot|            1|[0.0, 24.725115, ...|\n",
      "|Data/Apricot/1_10...|Apricot|            1|[0.0, 18.634443, ...|\n",
      "|Data/Avocado/0_10...|Avocado|            2|[0.0, 48.943558, ...|\n",
      "+--------------------+-------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# On vérifie\n",
    "features_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "108f49cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On transforme nos données en vecteurs\n",
    "list_to_vector_udf = udf(lambda l: Vectors.dense(l), VectorUDT())\n",
    "features_df = features_df.select(col('path'),  col('label'),\n",
    "                                 list_to_vector_udf(features_df['features']).alias('features_vect'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b8ddc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- path: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      " |-- features_vect: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# On vérifie\n",
    "features_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1f3995a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<botocore.response.StreamingBody object at 0x7fd69330ee50>          (0 + 2) / 2]\n",
      "<botocore.response.StreamingBody object at 0x7fd69386b110>\n",
      "<botocore.response.StreamingBody object at 0x7fd69332bc90>\n",
      "<botocore.response.StreamingBody object at 0x7fd693545510>\n",
      "<botocore.response.StreamingBody object at 0x7fd693a42b10>\n",
      "<botocore.response.StreamingBody object at 0x7fd693326650>\n",
      "<botocore.response.StreamingBody object at 0x7fd69330e790>\n",
      "<botocore.response.StreamingBody object at 0x7fd6935739d0>\n",
      "<botocore.response.StreamingBody object at 0x7fd6939e0d10>\n",
      "<botocore.response.StreamingBody object at 0x7fd693a05050>\n",
      "2022-10-23 05:23:59.741408: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-23 05:23:59.746622: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300035000 Hz\n",
      "2022-10-23 05:23:59.746789: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cce5c77de0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-10-23 05:23:59.746807: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-10-23 05:24:05.695298: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 14208640 exceeds 10% of free system memory.\n",
      "2022-10-23 05:24:05.788463: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 13829760 exceeds 10% of free system memory.\n",
      "2022-10-23 05:24:05.868497: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 27659520 exceeds 10% of free system memory.\n",
      "2022-10-23 05:24:06.002275: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 19357440 exceeds 10% of free system memory.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# On standardise nos données\n",
    "standardizer = StandardScaler(withMean=True, withStd=True,\n",
    "                              inputCol='features_vect',\n",
    "                              outputCol='feats_scaled')\n",
    "std = standardizer.fit(features_df)\n",
    "features_df_scaled = std.transform(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91d446ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- path: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      " |-- features_vect: vector (nullable = true)\n",
      " |-- feats_scaled: vector (nullable = true)\n",
      "\n",
      "22/10/23 05:24:10 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<botocore.response.StreamingBody object at 0x7fd693549410>          (0 + 1) / 1]\n",
      "<botocore.response.StreamingBody object at 0x7fd6937b4ed0>\n",
      "<botocore.response.StreamingBody object at 0x7fd693a05310>\n",
      "<botocore.response.StreamingBody object at 0x7fd693549b50>\n",
      "<botocore.response.StreamingBody object at 0x7fd6932f7d50>\n",
      "2022-10-23 05:24:31.190200: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-23 05:24:31.275169: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300035000 Hz\n",
      "2022-10-23 05:24:31.276281: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cce62307a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-10-23 05:24:31.276409: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-10-23 05:25:43.128453: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 14208640 exceeds 10% of free system memory.\n",
      "2022-10-23 05:25:43.212464: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 13829760 exceeds 10% of free system memory.\n",
      "2022-10-23 05:25:43.241024: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 27659520 exceeds 10% of free system memory.\n",
      "2022-10-23 05:25:43.309911: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 19357440 exceeds 10% of free system memory.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/23 05:25:47 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<botocore.response.StreamingBody object at 0x7fd647724c90>          (0 + 1) / 1]\n",
      "<botocore.response.StreamingBody object at 0x7fd66013b7d0>\n",
      "<botocore.response.StreamingBody object at 0x7fd6476c6610>\n",
      "<botocore.response.StreamingBody object at 0x7fd6604c3a50>\n",
      "<botocore.response.StreamingBody object at 0x7fd6476dc410>\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------------------+--------------------+\n",
      "|                path|  label|       features_vect|        feats_scaled|\n",
      "+--------------------+-------+--------------------+--------------------+\n",
      "|Data/Apple/0_100.jpg|  Apple|[15.9286146163940...|[1.70472518388399...|\n",
      "|Data/Apple/1_100.jpg|  Apple|[12.5887784957885...|[1.18987347967896...|\n",
      "|Data/Apricot/0_10...|Apricot|[0.0,24.725114822...|[-0.7507469065816...|\n",
      "|Data/Apricot/1_10...|Apricot|[0.0,18.634443283...|[-0.7507469065816...|\n",
      "|Data/Avocado/0_10...|Avocado|[0.0,48.943557739...|[-0.7507469065816...|\n",
      "+--------------------+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# On vérifie\n",
    "features_df_scaled.printSchema()\n",
    "features_df_scaled.show(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d501ea08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/23 05:27:19 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<botocore.response.StreamingBody object at 0x7fd693854dd0>          (0 + 1) / 1]\n",
      "<botocore.response.StreamingBody object at 0x7fd6935421d0>\n",
      "<botocore.response.StreamingBody object at 0x7fd693326310>\n",
      "<botocore.response.StreamingBody object at 0x7fd69356c3d0>\n",
      "<botocore.response.StreamingBody object at 0x7fd6937b8890>\n",
      "2022-10-23 05:27:42.414196: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-23 05:27:42.448318: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300035000 Hz\n",
      "2022-10-23 05:27:42.448631: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cce5c77de0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-10-23 05:27:42.448666: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/23 05:27:50 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<botocore.response.StreamingBody object at 0x7fd6939efa90>          (0 + 2) / 2]\n",
      "<botocore.response.StreamingBody object at 0x7fd641523a50>\n",
      "<botocore.response.StreamingBody object at 0x7fd6933022d0>\n",
      "<botocore.response.StreamingBody object at 0x7fd64142bfd0>\n",
      "<botocore.response.StreamingBody object at 0x7fd693bc5e50>\n",
      "<botocore.response.StreamingBody object at 0x7fd64144e710>\n",
      "<botocore.response.StreamingBody object at 0x7fd6932fe290>\n",
      "<botocore.response.StreamingBody object at 0x7fd6413a3250>\n",
      "<botocore.response.StreamingBody object at 0x7fd693b54f10>\n",
      "<botocore.response.StreamingBody object at 0x7fd64144ef90>\n",
      "2022-10-23 05:28:16.038107: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-23 05:28:16.043263: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300035000 Hz\n",
      "2022-10-23 05:28:16.043489: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cce5c77de0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-10-23 05:28:16.043532: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-10-23 05:28:16.333168: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-23 05:28:16.343359: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300035000 Hz\n",
      "2022-10-23 05:28:16.343646: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cce5c77de0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-10-23 05:28:16.343664: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/23 05:30:00 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<botocore.response.StreamingBody object at 0x7fd641523a50>          (0 + 1) / 1]\n",
      "<botocore.response.StreamingBody object at 0x7fd64142cfd0>\n",
      "<botocore.response.StreamingBody object at 0x7fd64144d710>\n",
      "<botocore.response.StreamingBody object at 0x7fd6413a0250>\n",
      "<botocore.response.StreamingBody object at 0x7fd64144df90>\n",
      "2022-10-23 05:30:20.223852: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-23 05:30:20.266388: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300035000 Hz\n",
      "2022-10-23 05:30:20.266669: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cce5c77de0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-10-23 05:30:20.266693: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/23 05:30:27 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/10/23 05:30:27 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "22/10/23 05:30:27 WARN RowMatrix: The input data is not directly cached, which may hurt performance if its parent RDDs are also uncached.\n",
      "22/10/23 05:30:27 WARN InstanceBuilder$NativeARPACK: Failed to load implementation from:dev.ludovic.netlib.arpack.JNIARPACK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/23 05:30:28 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<botocore.response.StreamingBody object at 0x7fd641589d50>          (0 + 2) / 2]\n",
      "<botocore.response.StreamingBody object at 0x7fd693853dd0>\n",
      "<botocore.response.StreamingBody object at 0x7fd6413b2290>\n",
      "<botocore.response.StreamingBody object at 0x7fd6935431d0>\n",
      "<botocore.response.StreamingBody object at 0x7fd641398610>\n",
      "<botocore.response.StreamingBody object at 0x7fd693326310>\n",
      "<botocore.response.StreamingBody object at 0x7fd641564810>\n",
      "<botocore.response.StreamingBody object at 0x7fd69356c3d0>\n",
      "<botocore.response.StreamingBody object at 0x7fd6415a8c10>\n",
      "<botocore.response.StreamingBody object at 0x7fd6937b8890>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/23 05:30:59 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "22/10/23 05:30:59 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 05:31:00.397564: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-23 05:31:00.502923: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300035000 Hz\n",
      "2022-10-23 05:31:00.504316: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cce5c77de0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-10-23 05:31:00.504340: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "[Stage 22:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/23 05:35:15 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 224295 ms exceeds timeout 120000 ms\n",
      "22/10/23 05:35:15 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 05:35:20.171485: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 14208640 exceeds 10% of free system memory.\n",
      "2022-10-23 05:35:20.257535: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 13829760 exceeds 10% of free system memory.\n",
      "2022-10-23 05:35:20.286360: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 27659520 exceeds 10% of free system memory.\n",
      "2022-10-23 05:35:20.396885: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 19357440 exceeds 10% of free system memory.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/23 05:35:24 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<botocore.response.StreamingBody object at 0x7fd641523a50>          (0 + 2) / 2]\n",
      "<botocore.response.StreamingBody object at 0x7fd6929b38d0>\n",
      "<botocore.response.StreamingBody object at 0x7fd64142bfd0>\n",
      "<botocore.response.StreamingBody object at 0x7fd692904650>\n",
      "<botocore.response.StreamingBody object at 0x7fd64144e710>\n",
      "<botocore.response.StreamingBody object at 0x7fd69286f810>\n",
      "<botocore.response.StreamingBody object at 0x7fd6413a3250>\n",
      "<botocore.response.StreamingBody object at 0x7fd6928ba310>\n",
      "<botocore.response.StreamingBody object at 0x7fd64144ef90>\n",
      "<botocore.response.StreamingBody object at 0x7fd692aeb790>\n",
      "2022-10-23 05:35:54.362076: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-23 05:35:54.362348: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-23 05:35:54.390371: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300035000 Hz\n",
      "2022-10-23 05:35:54.390371: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300035000 Hz\n",
      "2022-10-23 05:35:54.390630: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cce5c77de0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-10-23 05:35:54.390649: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-10-23 05:35:54.390908: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cce5c77de0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-10-23 05:35:54.390932: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/23 05:43:07 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<botocore.response.StreamingBody object at 0x7fd641523a50>          (0 + 2) / 2]\n",
      "<botocore.response.StreamingBody object at 0x7fd641523a50>\n",
      "<botocore.response.StreamingBody object at 0x7fd64142bfd0>\n",
      "<botocore.response.StreamingBody object at 0x7fd64142bfd0>\n",
      "<botocore.response.StreamingBody object at 0x7fd64144e710>\n",
      "<botocore.response.StreamingBody object at 0x7fd64144d710>\n",
      "<botocore.response.StreamingBody object at 0x7fd6413a3250>\n",
      "<botocore.response.StreamingBody object at 0x7fd6413a0250>\n",
      "<botocore.response.StreamingBody object at 0x7fd64144ef90>\n",
      "<botocore.response.StreamingBody object at 0x7fd64144df90>\n",
      "2022-10-23 05:43:39.078573: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-23 05:43:39.078567: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-23 05:43:39.133133: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300035000 Hz\n",
      "2022-10-23 05:43:39.133142: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300035000 Hz\n",
      "2022-10-23 05:43:39.134155: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cce5c77de0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-10-23 05:43:39.134155: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cce5c77de0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-10-23 05:43:39.134177: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-10-23 05:43:39.134178: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-10-23 05:54:09.315821: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 14208640 exceeds 10% of free system memory.\n",
      "2022-10-23 05:54:09.315845: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 14208640 exceeds 10% of free system memory.\n",
      "2022-10-23 05:54:09.406706: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 13829760 exceeds 10% of free system memory.\n",
      "2022-10-23 05:54:09.406706: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 13829760 exceeds 10% of free system memory.\n",
      "2022-10-23 05:54:09.462109: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 27659520 exceeds 10% of free system memory.\n",
      "2022-10-23 05:54:09.462473: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 27659520 exceeds 10% of free system memory.\n",
      "2022-10-23 05:54:09.588631: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 19357440 exceeds 10% of free system memory.\n",
      "2022-10-23 05:54:09.588635: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 19357440 exceeds 10% of free system memory.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/23 05:54:14 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<botocore.response.StreamingBody object at 0x7fd641ad8050>          (0 + 2) / 2]\n",
      "<botocore.response.StreamingBody object at 0x7fd6929b38d0>\n",
      "<botocore.response.StreamingBody object at 0x7fd6419e2550>\n",
      "<botocore.response.StreamingBody object at 0x7fd692904650>\n",
      "<botocore.response.StreamingBody object at 0x7fd641a6fe50>\n",
      "<botocore.response.StreamingBody object at 0x7fd69286f810>\n",
      "<botocore.response.StreamingBody object at 0x7fd641954610>\n",
      "<botocore.response.StreamingBody object at 0x7fd6928ba310>\n",
      "<botocore.response.StreamingBody object at 0x7fd641b45fd0>\n",
      "<botocore.response.StreamingBody object at 0x7fd692aeb790>\n",
      "2022-10-23 05:54:39.654418: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 14208640 exceeds 10% of free system memory.\n",
      "2022-10-23 05:56:48.515489: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-23 05:56:48.641526: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300035000 Hz\n",
      "2022-10-23 05:56:48.643664: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cce5c77de0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-10-23 05:56:48.643686: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/23 05:56:57 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<botocore.response.StreamingBody object at 0x7fd6929b38d0>          (0 + 2) / 2]\n",
      "<botocore.response.StreamingBody object at 0x7fd641523a50>\n",
      "<botocore.response.StreamingBody object at 0x7fd64142bfd0>\n",
      "<botocore.response.StreamingBody object at 0x7fd692903650>\n",
      "<botocore.response.StreamingBody object at 0x7fd69286f810>\n",
      "<botocore.response.StreamingBody object at 0x7fd64144d710>\n",
      "<botocore.response.StreamingBody object at 0x7fd6413a0250>\n",
      "<botocore.response.StreamingBody object at 0x7fd6928b9310>\n",
      "<botocore.response.StreamingBody object at 0x7fd64144df90>\n",
      "<botocore.response.StreamingBody object at 0x7fd692aeb790>\n",
      "2022-10-23 05:57:20.668365: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-23 05:57:20.668427: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-23 05:57:20.673568: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300035000 Hz\n",
      "2022-10-23 05:57:20.674196: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300035000 Hz\n",
      "2022-10-23 05:57:20.674354: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cce5c77de0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-10-23 05:57:20.674368: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-10-23 05:57:20.674553: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cce5c77de0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-10-23 05:57:20.674594: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-10-23 05:58:55.491883: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 27659520 exceeds 10% of free system memory.\n",
      "2022-10-23 05:58:55.774938: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 27659520 exceeds 10% of free system memory.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/23 05:59:02 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<botocore.response.StreamingBody object at 0x7fd64d523a50>          (0 + 2) / 2]\n",
      "<botocore.response.StreamingBody object at 0x7fd6929b38d0>\n",
      "<botocore.response.StreamingBody object at 0x7fd64d42bfd0>\n",
      "<botocore.response.StreamingBody object at 0x7fd692903650>\n",
      "<botocore.response.StreamingBody object at 0x7fd64d44d710>\n",
      "<botocore.response.StreamingBody object at 0x7fd69286f810>\n",
      "<botocore.response.StreamingBody object at 0x7fd64d3a0250>\n",
      "<botocore.response.StreamingBody object at 0x7fd6928b9310>\n",
      "<botocore.response.StreamingBody object at 0x7fd64d44df90>\n",
      "<botocore.response.StreamingBody object at 0x7fd692aeb790>\n",
      "2022-10-23 05:59:26.206670: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 27659520 exceeds 10% of free system memory.\n",
      "2022-10-23 06:00:23.397314: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-23 06:00:23.686588: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300035000 Hz\n",
      "2022-10-23 06:00:23.699865: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cce5c77de0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-10-23 06:00:23.699903: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "[Stage 27:=============================>                            (1 + 1) / 2]\r"
     ]
    }
   ],
   "source": [
    "pca = PCA(k=4, inputCol='feats_scaled', outputCol='pca')\n",
    "modelpca = pca.fit(features_df_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd70be23",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = modelpca.transform(features_df_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81524d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On regarde la variance expliquée par nos nouvelles données\n",
    "variance_explained = modelpca.explainedVariance\n",
    "variance_explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4fe391",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df_pandas = transformed.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e84d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19550be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3', aws_access_key_id=aws_key_id, aws_secret_access_key=aws_secret_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd10fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_obj = StringIO()\n",
    "images_df_pandas.to_csv(csv_obj)\n",
    "s3.Object(\"ocproj8\", \"Features/results_sample_cloud_2.csv\").put(Body=csv_obj.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf35c2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enregistre dans un nouveau dossier dans notre bucket S3\n",
    "features_df_scaled.write.parquet(path='s3://ocproj8/Feature/', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab093d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d46acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b90432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f8eb3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70da8826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fa45a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
